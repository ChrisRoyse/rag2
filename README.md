# RAG System with Nomic Embeddings

A high-performance Retrieval-Augmented Generation (RAG) system built in Rust, featuring advanced embeddings with Nomic-Embed, intelligent caching, and comprehensive search capabilities.

## ğŸš€ Features

### Core Capabilities
- **Nomic-Embed Integration**: State-of-the-art code embeddings using nomic-embed-code model
- **Multi-Modal Search**: Hybrid search combining BM25, vector similarity, and fuzzy matching
- **Intelligent Caching**: Three-tier caching system with memory optimization
- **Real-Time Monitoring**: Git watcher for automatic index updates
- **MCP Server**: Model Context Protocol server for AI integration

### Performance Optimizations
- Zero-copy memory operations
- SIMD-accelerated vector operations  
- Bounded cache with LRU eviction
- Lazy loading and streaming embeddings
- Optimized memory pool management

## ğŸ“ Project Structure

```
rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embedding/          # Nomic embeddings implementation
â”‚   â”œâ”€â”€ search/             # Search algorithms (BM25, Tantivy, fuzzy)
â”‚   â”œâ”€â”€ storage/            # LanceDB and vector storage
â”‚   â”œâ”€â”€ cache/              # Caching implementations
â”‚   â”œâ”€â”€ memory/             # Memory optimization utilities
â”‚   â”œâ”€â”€ mcp/                # Model Context Protocol server
â”‚   â””â”€â”€ git/                # Git integration and watchers
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ embedding_migration/    # Migration test suite
â”‚   â”œâ”€â”€ validation/            # Component validation tests
â”‚   â””â”€â”€ benchmarks/           # Performance benchmarks
â””â”€â”€ docs/
    â”œâ”€â”€ embedplan/            # Embedding migration plans
    â””â”€â”€ swarmop/              # Swarm optimization guides
```

## ğŸ› ï¸ Installation

### Prerequisites
- Rust 1.75+ with cargo
- Node.js 18+ (for MCP server)
- Git

### Build Instructions

```bash
# Clone the repository
git clone https://github.com/yourusername/rag.git
cd rag

# Build the project
cargo build --release

# Run tests
cargo test

# Run with optimizations
cargo run --release
```

## ğŸ§ª Testing

### Run Complete Test Suite
```bash
# All tests
cargo test

# Embedding tests only
cargo test --test embedding_test

# Integration tests
cargo test --test brutal_integration_test

# Benchmarks
cargo bench
```

### Validation Scripts
```bash
# Run embedding migration tests
./scripts/run_embedding_tests.sh

# Validate test structure
./scripts/validate_test_structure.sh

# Run swarm migration
./scripts/swarm-embeddings-migration.sh
```

## ğŸ—ï¸ Architecture

### Component Overview

1. **Embedding System**
   - Nomic-Embed model integration via llama.cpp
   - Streaming embeddings with backpressure
   - Intelligent caching with TTL

2. **Search Infrastructure**
   - BM25 for keyword search
   - Vector similarity for semantic search
   - Fuzzy matching for approximate search
   - Hybrid fusion with configurable weights

3. **Storage Layer**
   - LanceDB for vector storage
   - In-memory cache for hot data
   - Persistent storage with zero-copy operations

4. **Memory Management**
   - Bounded caches with configurable limits
   - Memory pool for vector operations
   - Automatic garbage collection

## ğŸ“Š Performance Metrics

- **Embedding Speed**: ~1000 tokens/second
- **Search Latency**: <10ms for cached queries
- **Memory Usage**: <500MB for 100k documents
- **Cache Hit Rate**: >90% for common queries

## ğŸ”§ Configuration

Create a `config.toml` file:

```toml
[embedding]
model_path = "model/nomic-embed-code.Q4_K_M.gguf"
dimension = 768
batch_size = 32

[cache]
max_size = 10000
ttl_seconds = 3600

[search]
bm25_weight = 0.5
vector_weight = 0.5
result_limit = 20
```

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines.

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- Nomic AI for the embedding models
- The Rust community for excellent libraries
- Claude-Flow for orchestration capabilities

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check the [documentation](docs/)
- Review the [troubleshooting guide](TROUBLESHOOTING.md)